{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: torch in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.47.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kyryl\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kyryl\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kyryl\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kyryl\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kyryl\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kyryl\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy matplotlib pandas scikit-learn torch torchvision transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = trainset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # денормалізація\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamster turtle poppy  pear\n"
     ]
    }
   ],
   "source": [
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "model = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "def extract_features(images):\n",
    "    inputs = feature_extractor(images=list(images), return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "batch_size_features = 32\n",
    "\n",
    "def extract_all_features(dataset):\n",
    "    all_features = []\n",
    "    for i in range(0, len(dataset), batch_size_features):\n",
    "        batch = dataset.data[i:i + batch_size_features]\n",
    "        features = extract_features(batch)\n",
    "        all_features.extend(features)\n",
    "    return np.array(all_features)\n",
    "\n",
    "def extract_all_features_sample(dataset, sample_size):\n",
    "    all_features = []\n",
    "    for i in range(0, min(len(dataset), sample_size), batch_size_features):\n",
    "        batch = dataset.data[i:i + batch_size_features]\n",
    "        features = extract_features(batch)\n",
    "        all_features.extend(features)\n",
    "    return np.array(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (k-NN on raw pixels - Subset):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           6       0.05      0.50      0.09         2\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.33      0.50      0.40         2\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         2\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.25      1.00      0.40         1\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         1\n",
      "          27       0.11      0.50      0.18         2\n",
      "          29       0.00      0.00      0.00         2\n",
      "          32       0.00      0.00      0.00         3\n",
      "          33       0.00      0.00      0.00         2\n",
      "          35       0.00      0.00      0.00         2\n",
      "          37       0.00      0.00      0.00         2\n",
      "          39       0.00      0.00      0.00         1\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         2\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         2\n",
      "          47       0.00      0.00      0.00         0\n",
      "          49       0.00      0.00      0.00         3\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.00      0.00      0.00         1\n",
      "          54       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         2\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         2\n",
      "          61       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         1\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         2\n",
      "          69       0.00      0.00      0.00         2\n",
      "          70       0.00      0.00      0.00         3\n",
      "          71       0.33      0.25      0.29         4\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.00      0.00      0.00         2\n",
      "          75       0.00      0.00      0.00         4\n",
      "          77       0.00      0.00      0.00         2\n",
      "          78       0.00      0.00      0.00         2\n",
      "          81       0.00      0.00      0.00         1\n",
      "          82       0.00      0.00      0.00         2\n",
      "          89       0.00      0.00      0.00         1\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         1\n",
      "          92       0.00      0.00      0.00         3\n",
      "          93       0.00      0.00      0.00         1\n",
      "          97       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.05       100\n",
      "   macro avg       0.02      0.04      0.02       100\n",
      "weighted avg       0.03      0.05      0.03       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kyryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kyryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kyryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kyryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kyryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "sample_size_subset = 100  # Adjust this for subset size\n",
    "knn_raw = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_raw.fit(trainset.data.reshape(len(trainset), -1)[:sample_size_subset],\n",
    "            np.array(trainset.targets[:sample_size_subset]))\n",
    "predictions_raw = knn_raw.predict(testset.data.reshape(len(testset), -1)[:sample_size_subset])\n",
    "\n",
    "print(\"Classification Report (k-NN on raw pixels - Subset):\")\n",
    "print(classification_report(np.array(testset.targets[:sample_size_subset]), predictions_raw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (k-NN with ViT features - Subset):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         2\n",
      "           2       0.00      0.00      0.00         1\n",
      "           4       0.25      1.00      0.40         1\n",
      "           6       0.11      1.00      0.19         2\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.60      1.00      0.75         3\n",
      "           9       1.00      1.00      1.00         2\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       1.00      0.50      0.67         2\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.67      1.00      0.80         2\n",
      "          18       0.50      1.00      0.67         1\n",
      "          19       1.00      1.00      1.00         1\n",
      "          20       1.00      1.00      1.00         3\n",
      "          21       1.00      0.50      0.67         4\n",
      "          22       0.00      0.00      0.00         3\n",
      "          23       0.10      1.00      0.18         1\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         3\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.67      1.00      0.80         2\n",
      "          32       1.00      0.33      0.50         3\n",
      "          33       1.00      0.67      0.80         3\n",
      "          35       0.00      0.00      0.00         2\n",
      "          36       0.00      0.00      0.00         0\n",
      "          37       0.00      0.00      0.00         2\n",
      "          39       0.25      1.00      0.40         1\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         2\n",
      "          42       0.07      1.00      0.13         1\n",
      "          43       0.00      0.00      0.00         4\n",
      "          47       0.50      1.00      0.67         1\n",
      "          49       1.00      0.33      0.50         3\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       1.00      1.00      1.00         1\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.50      1.00      0.67         1\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       1.00      0.33      0.50         3\n",
      "          57       0.00      0.00      0.00         3\n",
      "          58       0.00      0.00      0.00         2\n",
      "          59       1.00      1.00      1.00         1\n",
      "          61       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00         0\n",
      "          65       0.00      0.00      0.00         1\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         2\n",
      "          69       1.00      0.67      0.80         3\n",
      "          70       1.00      0.67      0.80         3\n",
      "          71       0.67      0.80      0.73         5\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       1.00      0.50      0.67         2\n",
      "          75       1.00      1.00      1.00         4\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.00      0.00      0.00         2\n",
      "          78       1.00      1.00      1.00         2\n",
      "          81       0.00      0.00      0.00         1\n",
      "          82       0.00      0.00      0.00         2\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         0\n",
      "          85       0.00      0.00      0.00         1\n",
      "          89       0.17      1.00      0.29         1\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         1\n",
      "          92       0.00      0.00      0.00         4\n",
      "          93       0.00      0.00      0.00         1\n",
      "          95       0.00      0.00      0.00         1\n",
      "          97       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.41       128\n",
      "   macro avg       0.30      0.35      0.28       128\n",
      "weighted avg       0.41      0.41      0.37       128\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kyryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\kyryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n",
      "c:\\Users\\kyryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kyryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kyryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kyryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kyryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\kyryl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "sample_size_subset = 100  # Adjust this for subset size (same or different)\n",
    "train_features_subset = extract_all_features_sample(trainset, sample_size_subset)\n",
    "train_labels_subset = np.array(trainset.targets[:len(train_features_subset)])  # Use actual length\n",
    "\n",
    "test_features_subset = extract_all_features_sample(testset, sample_size_subset)\n",
    "test_labels_subset = np.array(testset.targets[:len(test_features_subset)])\n",
    "\n",
    "knn_vit = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_vit.fit(train_features_subset, train_labels_subset)\n",
    "predictions_vit_subset = knn_vit.predict(test_features_subset)\n",
    "\n",
    "print(\"\\nClassification Report (k-NN with ViT features - Subset):\")\n",
    "print(classification_report(test_labels_subset, predictions_vit_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (k-NN on raw pixels - Full):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.56      0.32       100\n",
      "           1       0.14      0.20      0.16       100\n",
      "           2       0.13      0.20      0.16       100\n",
      "           3       0.07      0.11      0.09       100\n",
      "           4       0.06      0.23      0.09       100\n",
      "           5       0.07      0.08      0.07       100\n",
      "           6       0.21      0.13      0.16       100\n",
      "           7       0.07      0.19      0.10       100\n",
      "           8       0.08      0.17      0.11       100\n",
      "           9       0.12      0.31      0.17       100\n",
      "          10       0.05      0.14      0.07       100\n",
      "          11       0.24      0.12      0.16       100\n",
      "          12       0.13      0.09      0.11       100\n",
      "          13       0.00      0.00      0.00       100\n",
      "          14       0.17      0.07      0.10       100\n",
      "          15       0.08      0.09      0.08       100\n",
      "          16       0.26      0.30      0.28       100\n",
      "          17       0.14      0.18      0.16       100\n",
      "          18       0.05      0.09      0.06       100\n",
      "          19       0.03      0.04      0.04       100\n",
      "          20       0.42      0.40      0.41       100\n",
      "          21       0.16      0.10      0.12       100\n",
      "          22       0.10      0.22      0.14       100\n",
      "          23       0.08      0.41      0.13       100\n",
      "          24       0.21      0.53      0.30       100\n",
      "          25       0.06      0.08      0.07       100\n",
      "          26       0.07      0.11      0.08       100\n",
      "          27       0.04      0.10      0.05       100\n",
      "          28       0.22      0.41      0.28       100\n",
      "          29       0.22      0.15      0.18       100\n",
      "          30       0.19      0.27      0.23       100\n",
      "          31       0.02      0.02      0.02       100\n",
      "          32       0.08      0.13      0.10       100\n",
      "          33       0.10      0.16      0.12       100\n",
      "          34       0.11      0.11      0.11       100\n",
      "          35       0.00      0.00      0.00       100\n",
      "          36       0.24      0.12      0.16       100\n",
      "          37       0.00      0.00      0.00       100\n",
      "          38       0.05      0.07      0.06       100\n",
      "          39       0.17      0.14      0.16       100\n",
      "          40       0.33      0.17      0.22       100\n",
      "          41       0.80      0.41      0.54       100\n",
      "          42       0.15      0.09      0.11       100\n",
      "          43       0.12      0.07      0.09       100\n",
      "          44       0.03      0.07      0.04       100\n",
      "          45       0.33      0.06      0.10       100\n",
      "          46       0.35      0.06      0.10       100\n",
      "          47       0.27      0.27      0.27       100\n",
      "          48       0.84      0.16      0.27       100\n",
      "          49       0.17      0.12      0.14       100\n",
      "          50       0.05      0.03      0.04       100\n",
      "          51       0.07      0.01      0.02       100\n",
      "          52       0.34      0.40      0.37       100\n",
      "          53       0.54      0.34      0.42       100\n",
      "          54       0.50      0.04      0.07       100\n",
      "          55       0.05      0.04      0.04       100\n",
      "          56       0.24      0.04      0.07       100\n",
      "          57       0.39      0.19      0.26       100\n",
      "          58       0.40      0.02      0.04       100\n",
      "          59       0.18      0.10      0.13       100\n",
      "          60       0.17      0.64      0.26       100\n",
      "          61       0.25      0.39      0.31       100\n",
      "          62       0.58      0.19      0.29       100\n",
      "          63       0.19      0.17      0.18       100\n",
      "          64       0.04      0.02      0.03       100\n",
      "          65       0.08      0.07      0.07       100\n",
      "          66       0.12      0.02      0.03       100\n",
      "          67       0.11      0.18      0.13       100\n",
      "          68       0.30      0.30      0.30       100\n",
      "          69       0.31      0.22      0.26       100\n",
      "          70       0.53      0.09      0.15       100\n",
      "          71       0.12      0.49      0.19       100\n",
      "          72       0.00      0.00      0.00       100\n",
      "          73       0.25      0.25      0.25       100\n",
      "          74       0.27      0.08      0.12       100\n",
      "          75       0.19      0.05      0.08       100\n",
      "          76       0.35      0.26      0.30       100\n",
      "          77       0.04      0.03      0.04       100\n",
      "          78       0.00      0.00      0.00       100\n",
      "          79       0.08      0.15      0.11       100\n",
      "          80       0.17      0.04      0.07       100\n",
      "          81       0.00      0.00      0.00       100\n",
      "          82       0.78      0.29      0.42       100\n",
      "          83       0.33      0.02      0.04       100\n",
      "          84       0.11      0.01      0.02       100\n",
      "          85       0.33      0.06      0.10       100\n",
      "          86       0.62      0.16      0.25       100\n",
      "          87       0.38      0.10      0.16       100\n",
      "          88       0.00      0.00      0.00       100\n",
      "          89       0.00      0.00      0.00       100\n",
      "          90       0.60      0.03      0.06       100\n",
      "          91       0.48      0.30      0.37       100\n",
      "          92       0.31      0.04      0.07       100\n",
      "          93       0.16      0.04      0.06       100\n",
      "          94       0.32      0.33      0.32       100\n",
      "          95       0.52      0.11      0.18       100\n",
      "          96       0.10      0.10      0.10       100\n",
      "          97       0.61      0.11      0.19       100\n",
      "          98       1.00      0.02      0.04       100\n",
      "          99       0.12      0.16      0.14       100\n",
      "\n",
      "    accuracy                           0.15     10000\n",
      "   macro avg       0.22      0.15      0.14     10000\n",
      "weighted avg       0.22      0.15      0.14     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_raw = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_raw.fit(trainset.data.reshape(len(trainset), -1), np.array(trainset.targets))\n",
    "predictions_raw = knn_raw.predict(testset.data.reshape(len(testset), -1))\n",
    "\n",
    "print(\"\\nClassification Report (k-NN on raw pixels - Full):\")\n",
    "print(classification_report(np.array(testset.targets), predictions_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (k-NN with ViT features - Full):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       100\n",
      "           1       0.91      0.96      0.93       100\n",
      "           2       0.62      0.84      0.71       100\n",
      "           3       0.76      0.84      0.80       100\n",
      "           4       0.57      0.74      0.65       100\n",
      "           5       0.82      0.93      0.87       100\n",
      "           6       0.84      0.90      0.87       100\n",
      "           7       0.80      0.78      0.79       100\n",
      "           8       0.91      0.93      0.92       100\n",
      "           9       0.86      0.89      0.88       100\n",
      "          10       0.63      0.57      0.60       100\n",
      "          11       0.51      0.57      0.54       100\n",
      "          12       0.79      0.84      0.82       100\n",
      "          13       0.88      0.75      0.81       100\n",
      "          14       0.80      0.86      0.83       100\n",
      "          15       0.82      0.88      0.85       100\n",
      "          16       0.89      0.89      0.89       100\n",
      "          17       0.85      0.93      0.89       100\n",
      "          18       0.71      0.79      0.75       100\n",
      "          19       0.88      0.91      0.90       100\n",
      "          20       0.84      0.93      0.88       100\n",
      "          21       0.86      0.97      0.91       100\n",
      "          22       0.90      0.88      0.89       100\n",
      "          23       0.66      0.80      0.72       100\n",
      "          24       0.88      0.90      0.89       100\n",
      "          25       0.74      0.75      0.74       100\n",
      "          26       0.70      0.76      0.73       100\n",
      "          27       0.70      0.73      0.72       100\n",
      "          28       0.70      0.91      0.79       100\n",
      "          29       0.73      0.80      0.77       100\n",
      "          30       0.83      0.85      0.84       100\n",
      "          31       0.94      0.89      0.91       100\n",
      "          32       0.84      0.81      0.82       100\n",
      "          33       0.73      0.69      0.71       100\n",
      "          34       0.84      0.86      0.85       100\n",
      "          35       0.54      0.45      0.49       100\n",
      "          36       0.90      0.94      0.92       100\n",
      "          37       0.85      0.81      0.83       100\n",
      "          38       0.82      0.92      0.87       100\n",
      "          39       0.93      0.97      0.95       100\n",
      "          40       0.83      0.86      0.85       100\n",
      "          41       0.99      0.96      0.97       100\n",
      "          42       0.86      0.78      0.82       100\n",
      "          43       0.92      0.85      0.89       100\n",
      "          44       0.76      0.74      0.75       100\n",
      "          45       0.75      0.65      0.70       100\n",
      "          46       0.75      0.74      0.74       100\n",
      "          47       0.65      0.66      0.66       100\n",
      "          48       0.98      0.96      0.97       100\n",
      "          49       0.84      0.94      0.89       100\n",
      "          50       0.77      0.81      0.79       100\n",
      "          51       0.91      0.95      0.93       100\n",
      "          52       0.61      0.70      0.65       100\n",
      "          53       0.96      1.00      0.98       100\n",
      "          54       0.91      0.88      0.89       100\n",
      "          55       0.69      0.61      0.65       100\n",
      "          56       0.90      0.95      0.93       100\n",
      "          57       0.96      0.86      0.91       100\n",
      "          58       0.93      0.94      0.94       100\n",
      "          59       0.79      0.70      0.74       100\n",
      "          60       0.81      0.80      0.80       100\n",
      "          61       0.79      0.81      0.80       100\n",
      "          62       0.89      0.92      0.91       100\n",
      "          63       0.85      0.68      0.76       100\n",
      "          64       0.90      0.75      0.82       100\n",
      "          65       0.89      0.85      0.87       100\n",
      "          66       0.93      0.79      0.85       100\n",
      "          67       0.88      0.78      0.83       100\n",
      "          68       0.88      0.91      0.90       100\n",
      "          69       0.84      0.87      0.86       100\n",
      "          70       0.91      0.90      0.90       100\n",
      "          71       0.79      0.80      0.80       100\n",
      "          72       0.67      0.76      0.71       100\n",
      "          73       0.83      0.85      0.84       100\n",
      "          74       0.75      0.63      0.68       100\n",
      "          75       0.97      0.94      0.95       100\n",
      "          76       0.95      0.87      0.91       100\n",
      "          77       0.92      0.85      0.89       100\n",
      "          78       0.91      0.91      0.91       100\n",
      "          79       0.92      0.82      0.87       100\n",
      "          80       0.82      0.77      0.79       100\n",
      "          81       0.82      0.77      0.79       100\n",
      "          82       0.97      0.93      0.95       100\n",
      "          83       0.95      0.95      0.95       100\n",
      "          84       0.86      0.83      0.85       100\n",
      "          85       0.93      0.87      0.90       100\n",
      "          86       0.97      0.89      0.93       100\n",
      "          87       0.84      0.83      0.83       100\n",
      "          88       0.93      0.82      0.87       100\n",
      "          89       0.91      0.97      0.94       100\n",
      "          90       0.81      0.87      0.84       100\n",
      "          91       0.92      0.85      0.89       100\n",
      "          92       0.94      0.81      0.87       100\n",
      "          93       0.86      0.81      0.84       100\n",
      "          94       0.86      0.88      0.87       100\n",
      "          95       0.93      0.89      0.91       100\n",
      "          96       0.78      0.66      0.71       100\n",
      "          97       0.96      0.86      0.91       100\n",
      "          98       0.81      0.64      0.72       100\n",
      "          99       0.92      0.86      0.89       100\n",
      "\n",
      "    accuracy                           0.83     10000\n",
      "   macro avg       0.84      0.83      0.83     10000\n",
      "weighted avg       0.84      0.83      0.83     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_features = extract_all_features(trainset)\n",
    "test_features = extract_all_features(testset)\n",
    "\n",
    "train_labels = np.array(trainset.targets)\n",
    "test_labels = np.array(testset.targets)\n",
    "\n",
    "knn_vit = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_vit.fit(train_features, train_labels)\n",
    "predictions_vit = knn_vit.predict(test_features)\n",
    "\n",
    "print(\"\\nClassification Report (k-NN with ViT features - Full):\")\n",
    "print(classification_report(test_labels, predictions_vit))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
